# WTS : The price change in Seoul district 


```python
import pandas as pd
import numpy as np
```

read the excel file. We use the __real estate data__ from KB LiiV .


```python
df_Seoul = pd.read_excel('data(95to07).xlsx', sheet_name='price', header=0, skipfooter=0, usecols="A:B")
```

We want to make the new variables such as 'p_rate' , 'p_dot'  
**'p_rate'**(; the growth-rate of Seoul area) will be used to make x   
**'p_dot'** (; the rate of change of condominium price = 100 means that the price is unchanged)


```python
df_Seoul['L1_Seoul'] = df_Seoul['Seoul'].shift(1)
```


```python
df_Seoul['p_rate'] = (df_Seoul['Seoul'] / df_Seoul['L1_Seoul'] - 1) * 100
```


```python
df_Seoul['p_dot'] = (df_Seoul['Seoul'] / df_Seoul['L1_Seoul']) * 100
```

we don't use 'L1_Seoul' column anymore. __To fill the empty data of 'p-dot' & 'p-rate'__ remove 'L1_Seoul'


```python
df_Seoul = df_Seoul.drop('L1_Seoul', axis=1)
```


```python
df_Seoul = df_Seoul.fillna(method='bfill')
```

using the 'for' , we can make the variable 'x'


```python
df_Seoul['x0'] = np.where(df_Seoul['p_rate'] < 0, -1, 1)
```


```python
df_Seoul['cum_x0'] = df_Seoul['x0']
```


```python
for i in range(len(df_Seoul)):
    if i == 0:
        if df_Seoul['x0'][i] == 1:
            df_Seoul['cum_x0'][i] = 1
        else:
            df_Seoul['cum_x0'][i] = 0
    else:
        if df_Seoul['x0'][i] == df_Seoul['x0'][i - 1]:
            df_Seoul['cum_x0'][i] = df_Seoul['cum_x0'][i - 1] + df_Seoul['x0'][i]
        else:
            df_Seoul['cum_x0'][i] = df_Seoul['x0'][i]
```

    C:\Users\a\anaconda3\lib\site-packages\ipykernel_launcher.py:4: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame
    
    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
      after removing the cwd from sys.path.
    C:\Users\a\anaconda3\lib\site-packages\ipykernel_launcher.py:9: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame
    
    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
      if __name__ == '__main__':
    C:\Users\a\anaconda3\lib\site-packages\ipykernel_launcher.py:11: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame
    
    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
      # This is added back by InteractiveShellApp.init_path()
    

Make the variable 'x', 'x' means the number of periods in the current house price growth regime.


```python
df_Seoul['x'] = df_Seoul['cum_x0']
```


```python
df_Seoul = df_Seoul.drop(['x0', 'cum_x0'], axis=1)
```

**Chonsei**


```python
df_Seoul_ch = pd.read_excel('data(95to07).xlsx', sheet_name='chonsei', header=0, skipfooter=0, usecols="B")
```


```python
df_Seoul_ch = df_Seoul_ch.rename({'Seoul':'Seoul_ch'},axis=1)
```


```python
df_Seoul = pd.concat([df_Seoul, df_Seoul_ch], axis=1)
```

**Sovereign yield**


```python
df_sovereign = pd.read_excel('data(95to07).xlsx', sheet_name='sovereign yield', header=0, skipfooter=0, usecols="B")
```


```python
df_Seoul = pd.concat([df_Seoul, df_sovereign], axis=1)
```

Make the variable R(rent), C(rent-price ratio), b(chonesei-price ratio) , i(sovereign yield)


```python
df_Seoul['R'] = df_Seoul['Seoul_ch'] * df_Seoul['sovereign yield']
```


```python
df_Seoul['c'] = df_Seoul['R'] / df_Seoul['Seoul']
```


```python
df_Seoul['b'] = df_Seoul['Seoul_ch'] / df_Seoul['Seoul']
```


```python
df_Se = df_Seoul.rename({'sovereign yield': 'i'}, axis=1)
```


```python
df_Se['p_dot-1'] = df_Se['p_dot'].shift(3)
```


```python
df_Se = df_Se.fillna(method='bfill')
```

### In the df_SE, we can identify the variables to calculate the regression.


```python
df_Se['lnP'] = np.log(df_Se['p_dot'])
```


```python
df_Se['lnP-1'] = np.log(df_Se['p_dot-1'])
```


```python
df_Se['lnc'] = np.log(df_Se['c'])
```


```python
df_Se['lni'] = np.log(df_Se['i'])
```


```python
df_Se['lnb'] = np.log(df_Se['b'])
```


```python
df_SE = df_Se.drop({'Seoul','Seoul_ch','R','p_dot','p_dot-1','i','c','b','p_rate'}, axis=1)
```

#### The way to arrange dataframe : df = df[['e','c','b','f','d','a']]


```python
df_SE = df_SE[['lnP','lnb','lnc','lnP-1','x','lni']]
```

#### export to excel


```python
df_SE.to_excel('Seoul_95to07.xlsx')
```

#### make the regression


```python
import statsmodels.api as sm
import statsmodels.formula.api as smf
import matplotlib as plt
import seaborn as sns
```

Set the dependent variable (Y), independent variable(X: vector)  
## regression 1)


```python
Y = df_SE['lnP']
```


```python
X1 = df_SE[['lnc', 'lnP-1', 'x']]
```


```python
X1m = sm.add_constant(X1)
```


```python
K1m = sm.OLS(Y, X1m).fit()
```


```python
K1m.summary()
```




<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>           <td>lnP</td>       <th>  R-squared:         </th> <td>   0.543</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.533</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   54.63</td>
</tr>
<tr>
  <th>Date:</th>             <td>Wed, 17 Feb 2021</td> <th>  Prob (F-statistic):</th> <td>2.43e-23</td>
</tr>
<tr>
  <th>Time:</th>                 <td>20:47:33</td>     <th>  Log-Likelihood:    </th> <td>  446.02</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>   142</td>      <th>  AIC:               </th> <td>  -884.0</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>   138</td>      <th>  BIC:               </th> <td>  -872.2</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>const</th> <td>    6.0087</td> <td>    0.301</td> <td>   19.980</td> <td> 0.000</td> <td>    5.414</td> <td>    6.603</td>
</tr>
<tr>
  <th>lnc</th>   <td>   -0.0051</td> <td>    0.002</td> <td>   -2.785</td> <td> 0.006</td> <td>   -0.009</td> <td>   -0.001</td>
</tr>
<tr>
  <th>lnP-1</th> <td>   -0.3024</td> <td>    0.065</td> <td>   -4.640</td> <td> 0.000</td> <td>   -0.431</td> <td>   -0.174</td>
</tr>
<tr>
  <th>x</th>     <td>    0.0020</td> <td>    0.000</td> <td>   11.857</td> <td> 0.000</td> <td>    0.002</td> <td>    0.002</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>17.180</td> <th>  Durbin-Watson:     </th> <td>   1.094</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  55.841</td>
</tr>
<tr>
  <th>Skew:</th>          <td>-0.281</td> <th>  Prob(JB):          </th> <td>7.48e-13</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 6.020</td> <th>  Cond. No.          </th> <td>2.67e+03</td>
</tr>
</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.67e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems.



## regression 2)


```python
X2 = df_SE[['lnc','lnP-1','x','lni']]
```


```python
X2m = sm.add_constant(X2)
```


```python
K2m = sm.OLS(Y,X2m).fit()
```


```python
K2m.summary()
```




<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>           <td>lnP</td>       <th>  R-squared:         </th> <td>   0.574</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.562</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   46.23</td>
</tr>
<tr>
  <th>Date:</th>             <td>Wed, 17 Feb 2021</td> <th>  Prob (F-statistic):</th> <td>1.55e-24</td>
</tr>
<tr>
  <th>Time:</th>                 <td>20:47:33</td>     <th>  Log-Likelihood:    </th> <td>  451.09</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>   142</td>      <th>  AIC:               </th> <td>  -892.2</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>   137</td>      <th>  BIC:               </th> <td>  -877.4</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>const</th> <td>    6.2368</td> <td>    0.300</td> <td>   20.796</td> <td> 0.000</td> <td>    5.644</td> <td>    6.830</td>
</tr>
<tr>
  <th>lnc</th>   <td>    0.0185</td> <td>    0.008</td> <td>    2.433</td> <td> 0.016</td> <td>    0.003</td> <td>    0.033</td>
</tr>
<tr>
  <th>lnP-1</th> <td>   -0.3495</td> <td>    0.065</td> <td>   -5.392</td> <td> 0.000</td> <td>   -0.478</td> <td>   -0.221</td>
</tr>
<tr>
  <th>x</th>     <td>    0.0018</td> <td>    0.000</td> <td>   11.151</td> <td> 0.000</td> <td>    0.002</td> <td>    0.002</td>
</tr>
<tr>
  <th>lni</th>   <td>   -0.0283</td> <td>    0.009</td> <td>   -3.186</td> <td> 0.002</td> <td>   -0.046</td> <td>   -0.011</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>14.822</td> <th>  Durbin-Watson:     </th> <td>   1.164</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  50.432</td>
</tr>
<tr>
  <th>Skew:</th>          <td>-0.069</td> <th>  Prob(JB):          </th> <td>1.12e-11</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 5.916</td> <th>  Cond. No.          </th> <td>2.80e+03</td>
</tr>
</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.8e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems.



## regression 3)


```python
X3 = df_SE[['lnb', 'lnP-1', 'x', 'lni']]
```


```python
X3m = sm.add_constant(X3)
```


```python
K3m = sm.OLS(Y,X3m).fit()
```


```python
K3m.summary()
```




<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>           <td>lnP</td>       <th>  R-squared:         </th> <td>   0.574</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.562</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   46.23</td>
</tr>
<tr>
  <th>Date:</th>             <td>Wed, 17 Feb 2021</td> <th>  Prob (F-statistic):</th> <td>1.55e-24</td>
</tr>
<tr>
  <th>Time:</th>                 <td>20:47:33</td>     <th>  Log-Likelihood:    </th> <td>  451.09</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>   142</td>      <th>  AIC:               </th> <td>  -892.2</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>   137</td>      <th>  BIC:               </th> <td>  -877.4</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>const</th> <td>    6.2368</td> <td>    0.300</td> <td>   20.796</td> <td> 0.000</td> <td>    5.644</td> <td>    6.830</td>
</tr>
<tr>
  <th>lnb</th>   <td>    0.0185</td> <td>    0.008</td> <td>    2.433</td> <td> 0.016</td> <td>    0.003</td> <td>    0.033</td>
</tr>
<tr>
  <th>lnP-1</th> <td>   -0.3495</td> <td>    0.065</td> <td>   -5.392</td> <td> 0.000</td> <td>   -0.478</td> <td>   -0.221</td>
</tr>
<tr>
  <th>x</th>     <td>    0.0018</td> <td>    0.000</td> <td>   11.151</td> <td> 0.000</td> <td>    0.002</td> <td>    0.002</td>
</tr>
<tr>
  <th>lni</th>   <td>   -0.0099</td> <td>    0.002</td> <td>   -4.256</td> <td> 0.000</td> <td>   -0.014</td> <td>   -0.005</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>14.822</td> <th>  Durbin-Watson:     </th> <td>   1.164</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  50.432</td>
</tr>
<tr>
  <th>Skew:</th>          <td>-0.069</td> <th>  Prob(JB):          </th> <td>1.12e-11</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 5.916</td> <th>  Cond. No.          </th> <td>2.75e+03</td>
</tr>
</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.75e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems.


